# 데이터 탐색 보고서
---
## 사이트 분석 정보

### 크롤링한 사이트
- 잡코리아

### 크롤링한 사이트의 정보
![image](https://github.com/Playdata-G-DA35/DA35-2nd-goodjob-jobkorea/assets/130912864/cfe90665-fcbd-45a6-9620-fa06d01de73e)
- 잡코리아는 채용 플랫폼 중 하나이다. 주로 구직자와 기업 간의 매칭을 위한 다양한 기능과 정보를 제공하고 있다.
- 직무 조건을 버튼 클릭을 통하여 기업들을 조회할 수 있었으므로, url을 통해 페이지를 넘길 수 있는 구조가 아니었다.
- 그러므로 Selenium의 click() 함수를 통해 페이지를 넘겨야 했다.

![image](https://github.com/Playdata-G-DA35/DA35-2nd-goodjob-jobkorea/assets/130912864/bd793631-8cff-4674-810b-85caf75f39f8)
- 기업의 이름, 모집내용, 조건들을 조회하기 위해 nth-child를 제거하여 여러 tag들을 조회할 수 있는 CSS_SELECTOR를 활용해 정보를 크롤링 하였다.



### 크롤링한 페이지 캡처
- 기업명
![image](https://github.com/Playdata-G-DA35/DA35-2nd-goodjob-jobkorea/assets/130912864/7b4d9e50-5b57-463e-b2f1-13c235506d1a)

- 모집내용
![image](https://github.com/Playdata-G-DA35/DA35-2nd-goodjob-jobkorea/assets/130912864/1d8a0913-fe1c-455d-9177-14dd5b45aa6c)

- 조건
![image](https://github.com/Playdata-G-DA35/DA35-2nd-goodjob-jobkorea/assets/130912864/d1cc8529-6f7e-4cfe-91e8-1a14481353d6)


### selector
- **cor_name** : "#dev-gi-list > div > div.tplList.tplJobList > table > tbody > tr > td.tplCo > a"의 CSS_SELECTOR를 이용한 기업명 크롤링
- **recruitment_contents** : "#dev-gi-list > div > div.tplList.tplJobList > table > tbody > tr > td.tplTit > div > strong > a"의 CSS_SELECTOR를 활용한 모집내용 크롤링
- **conditions** : "#dev-gi-list > div > div.tplList.tplJobList > table > tbody > tr > td.tplTit > div > p.etc"의 CSS_SELECTOR를 이용한 조건 크롤링


### 어려웠던 점
- 모집공고를 클릭해서 들어가 회사가 원하는 채용 내용을 크롤링하는 것이 목표였지만 각 기업마다 공지해놓은 정보들의 형태가 각각 달랐기 때문에 데이터를 정형화 하기에 어려웠다.
- 기업 정보에 들어가서 text로 크롤링이 되지 않는 부분이 있었다.
- 직무에 맞는 조건을 클릭으로 해결해야 했기 때문에 url로 page를 넘길 수 있는 구조가 아니었다. 그러므로 Selenium으로만 해결해야 했다는 어려움이 있었다.
- MySQL과의 연동 시 데이터 중복이 발생하는 오류가 발생했다.

### 해결 방법
- Beautiful Soup 대신 Selenium을 사용하여 페이지를 버튼 클릭 형태로 넘겨가며 크롤링했다.
- DB로 저장하는 과정에서 1페이지의 정보를 크롤링 한 후 반복문을 2페이지부터 시작해야 데이터가 중복되지 않는다는 인사이트를 도출하였다.

### 프로젝트에서 사용한 기술
- **Selenium:** : 웹 페이지를 크롤링하는 도구로, 검색 조건 설정 및 데이터 수집에 사용된다.
- **CSS Selector:** : 웹 페이지의 특정 element를 선택하기 위한 패턴으로, Selenium에서 요소를 식별하고 조작하는 데 사용된다.
- **pandas:** : 수집한 데이터를 DataFrame으로 변환하고 CSV 파일로 저장한다.
- **pymysql:** MySQL 데이터베이스와 연동하여 데이터를 삽입, 조회하는데 사용된다.

---

## 데이터 셋
- **job.csv**
  - 잡코리아 기업명의 CSS_SELECTOR
  - 잡코리아 기업 모집내용의 CSS_SELECTOR
  - 채용조건의 CSS_SELECTOR
- 저장된 DB의 Table
![image](https://github.com/Playdata-G-DA35/DA35-2nd-goodjob-jobkorea/assets/130912864/0324d06f-5695-4834-97bf-6a6b6309d93a)
![image](https://github.com/Playdata-G-DA35/DA35-2nd-goodjob-jobkorea/assets/130912864/1af1c224-30d2-48f4-988e-ae679279397c)


### 크롤링한 데이터
- #dev-gi-list > div > div.tplList.tplJobList > table > tbody > tr > td.tplCo > a

- #dev-gi-list > div > div.tplList.tplJobList > table > tbody > tr > td.tplTit > div > strong > a

- #dev-gi-list > div > div.tplList.tplJobList > table > tbody > tr > td.tplTit > div > strong > a
